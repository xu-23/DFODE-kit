{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44caac4b",
   "metadata": {},
   "source": [
    "This is a tutorial for the DFODE-kit package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dfode_kit.df_interface import (\n",
    "    OneDFreelyPropagatingFlameConfig,\n",
    "    setup_one_d_flame_case,\n",
    "    df_to_h5,\n",
    ")\n",
    "from dfode_kit.data_operations import (\n",
    "    touch_h5, \n",
    "    get_TPY_from_h5, \n",
    "    random_perturb,\n",
    "    label_npy,\n",
    "    integrate_h5,\n",
    "    calculate_error,\n",
    ")\n",
    "from dfode_kit.dfode_core.model.mlp import MLP\n",
    "from dfode_kit.utils import BCT\n",
    "\n",
    "DFODE_ROOT = os.environ['DFODE_ROOT']\n",
    "\n",
    "print(DFODE_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032661c",
   "metadata": {},
   "source": [
    "### A brief introduction to the DFODE method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a592b7b",
   "metadata": {},
   "source": [
    "#### Low-dimensional manifold sampling\n",
    "\n",
    "A key challenge in preparing training data is achieving sufficient coverage of the relevant thermochemical composition space, which is often prohibitively high-dimensional when detailed chemistry involves tens to hundreds of species. \n",
    "\n",
    "To address this, DFODE-kit adopts a low-dimensional\n",
    "manifold sampling strategy, where thermochemical states are extracted from canonical flame configurations that retain the essential topology of high-dimensional turbulent flames. This approach ensures both computational efficiency and physical representativeness of the training datasets.\n",
    "\n",
    "In this tutorial, we will demonstrate how to use DFODE-kit to sample a low-dimensional manifold of thermochemical states from a one-dimensional laminar freely propagating flame simulated with DeepFlame. The following code block could also be found in `case_init.ipynb` files within the case templates provides in the `cases` directory. It is used to initialize the simulation and update the dictionary files for the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating condition settings\n",
    "config_dict = {\n",
    "    \"mechanism\": f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\",\n",
    "    \"T0\": 300,\n",
    "    \"p0\": 101325,\n",
    "    \"fuel\": \"H2:1\",\n",
    "    \"oxidizer\": \"O2:0.21,N2:0.79\",\n",
    "    \"eq_ratio\": 1.0,\n",
    "}\n",
    "config = OneDFreelyPropagatingFlameConfig(**config_dict)\n",
    "\n",
    "# Simulation settings\n",
    "settings = {\n",
    "    \"sim_time_step\": 1e-6,\n",
    "    \"sim_write_interval\": 1e-5,\n",
    "    \"num_output_steps\": 10,\n",
    "}\n",
    "config.update_config(settings)\n",
    "\n",
    "# Setup the case and update dictionary files\n",
    "setup_one_d_flame_case(config, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbe369",
   "metadata": {},
   "source": [
    "Note that at the point, the simulation is not yet started. The user would need to ensure a working version of DeepFlame is available and run the `Allrun` script from command line to start the simulation.\n",
    "\n",
    "```bash\n",
    "./Allrun\n",
    "```\n",
    "\n",
    "After the simulation is completed, we proceed to use DFODE-kit to gather and manage the thermochemical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_h5(\n",
    "    root_dir=f\"{DFODE_ROOT}/tutorials/oneD_freely_propagating_flame/1_sample_train\",\n",
    "    mechanism=f\"{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml\",\n",
    "    hdf5_file_path=f\"{DFODE_ROOT}/tutorials/oneD_freely_propagating_flame/1_sample_train/tutorial_data.h5\",\n",
    "    include_mesh=True,\n",
    ")\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit sample --mech ../../mechanisms/Burke2012_s9r23.yaml \\\n",
    "#     --case . \\\n",
    "#     --save ./tutorial_data.h5 --include_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991ab21",
   "metadata": {},
   "source": [
    "Checking the contents of the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_h5(\"tutorial_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779899a3",
   "metadata": {},
   "source": [
    "#### Data augmentation and labeling\n",
    "\n",
    "While laminar canonical flames provide fundamental thermochemical states,their trajectory-aligned sampling in composition space poses significant limitations for a posteriori modeling applications. First, these sampled states are confined to predefined flamelet manifolds, making the trained model highly sensitive to perturbations and leading to an over-constrained representation. Second, the sampled states span a lower-dimensional subspace, which fails to encompass the full range of thermochemical variations encountered in turbulent combustion. As a result, the model becomes vulnerable to off-manifold perturbationsâ€”deviations from the training manifold that frequently arise in turbulent reacting flows.\n",
    "\n",
    "To tackle this challenge, a data augmentation strategy is employed, where collected states are perturbed to simulate the effects of multi-dimensional transport and turbulence disturbances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece01cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5_file = 'tutorial_data.h5'\n",
    "mech = f'{DFODE_ROOT}/mechanisms/Burke2012_s9r23.yaml'\n",
    "dataset_num = 20000\n",
    "output_file = 'data'\n",
    "\n",
    "print(f\"Loading data from h5 file: {h5_file}\")\n",
    "data = get_TPY_from_h5(h5_file)    \n",
    "print(\"Data shape:\", data.shape)\n",
    "All_data = random_perturb(data, mech, dataset_num, heat_limit=False, element_limit=True)\n",
    "np.save(output_file, All_data)\n",
    "print(\"Saved augmented data shape:\", All_data.shape)\n",
    "print(f\"Saved augmented data to {output_file}\")\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit augment --mech ../../mechanisms/Burke2012_s9r23.yaml \\\n",
    "#     --h5_file ./tutorial_data.h5 \\\n",
    "#     --output_file ./data \\\n",
    "#     --dataset_num 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f2d8f",
   "metadata": {},
   "source": [
    "The CVODE integrator from Cantera is used for time integration and to provide supervised learning labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfode_kit.data_operations import label_npy\n",
    "\n",
    "try:\n",
    "    labeled_data = label_npy(\n",
    "        mech_path=mech,\n",
    "        time_step=1e-06,\n",
    "        source_path='./data.npy'\n",
    "    )\n",
    "    np.save('dataset.npy', labeled_data)\n",
    "    print(f\"Labeled data saved to: {'dataset.npy'}\")\n",
    "    \n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit label --mech ../../mechanisms/Burke2012_s9r23.yaml \\\n",
    "#     --time 1e-06 \\\n",
    "#     --source ./data.npy \\\n",
    "#     --save ./dataset.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc291e95",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "\n",
    "Only a demo for training a model is provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5aa0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cantera as ct\n",
    "from dfode_kit.dfode_core.train.formation import formation_calculate\n",
    "\n",
    "source_file = 'dataset.npy'\n",
    "time_step = 1e-06\n",
    "output_path = './demo_model.pt'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "labeled_data = np.load(source_file)\n",
    "\n",
    "gas = ct.Solution(mech)\n",
    "n_species = gas.n_species\n",
    "formation_enthalpies = formation_calculate(mech)\n",
    "\n",
    "# Model instantiation\n",
    "demo_model = MLP([2+n_species, 400, 400, 400, 400, n_species-1]).to(device)\n",
    "\n",
    "# Data loading\n",
    "thermochem_states1 = labeled_data[:, 0:2+n_species]\n",
    "thermochem_states2 = labeled_data[:, 2+n_species:]\n",
    "\n",
    "print(thermochem_states1.shape, thermochem_states2.shape)\n",
    "thermochem_states1[:, 2:] = np.clip(thermochem_states1[:, 2:], 0, 1)\n",
    "thermochem_states2[:, 2:] = np.clip(thermochem_states2[:, 2:], 0, 1)\n",
    "\n",
    "features = torch.tensor(BCT(thermochem_states1), dtype=torch.float32).to(device)\n",
    "labels = torch.tensor(BCT(thermochem_states2[:, 2:-1]) - BCT(thermochem_states1[:, 2:-1]), dtype=torch.float32).to(device)\n",
    "\n",
    "features_mean = torch.mean(features, dim=0)\n",
    "features_std = torch.std(features, dim=0)\n",
    "features = (features - features_mean) / features_std\n",
    "\n",
    "labels_mean = torch.mean(labels, dim=0)\n",
    "labels_std = torch.std(labels, dim=0)\n",
    "labels = (labels - labels_mean) / labels_std\n",
    "\n",
    "formation_enthalpies = torch.tensor(formation_enthalpies, dtype=torch.float32).to(device)\n",
    "\n",
    "# Training\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(demo_model.parameters(), lr=1e-3)\n",
    "\n",
    "demo_model.train()  \n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    preds = demo_model(features)\n",
    "    loss1 = loss_fn(preds, labels)   ## LOSS  \n",
    "\n",
    "    Y_in = ((features[:,2:-1]*features_std[2:-1] + features_mean[2:-1])*0.1 + 1)**10\n",
    "    Y_out = (((preds*labels_std + labels_mean) + (features[:,2:-1]*features_std[2:-1] + features_mean[2:-1]))*0.1 + 1)**10\n",
    "    Y_target = (((labels*labels_std + labels_mean) + (features[:,2:-1]*features_std[2:-1] + features_mean[2:-1]))*0.1 + 1)**10\n",
    "    loss2 = loss_fn(Y_out.sum(axis=1), Y_in.sum(axis=1))\n",
    "\n",
    "    Y_out_total = torch.cat((Y_out, (1-Y_out.sum(axis=1)).reshape(Y_out.shape[0],1)), axis = 1)\n",
    "    Y_target_total = torch.cat((Y_target, (1-Y_target.sum(axis=1)).reshape(Y_target.shape[0],1)), axis = 1)\n",
    "    loss3 = loss_fn((formation_enthalpies*Y_out_total).sum(axis=1), (formation_enthalpies*Y_target_total).sum(axis=1))/time_step\n",
    "\n",
    "    loss = loss1 + loss2 + loss3/1e+13\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: {}, Loss1: {:4e}, Loss2: {:4e}, Loss3: {:4e}, Loss: {:4e}\".format(epoch+1, loss1.item(), loss2.item(), loss3.item(), loss.item()))\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        'net': demo_model.state_dict(),\n",
    "        'data_in_mean': features_mean.cpu().numpy(),\n",
    "        'data_in_std': features_std.cpu().numpy(),\n",
    "        'data_target_mean': labels_mean.cpu().numpy(),\n",
    "        'data_target_std': labels_std.cpu().numpy(),\n",
    "    },\n",
    "    output_path\n",
    ")\n",
    "\n",
    "# The above is equivalent to the following cli command:\n",
    "# dfode-kit train --mech ../../mechanisms/Burke2012_s9r23.yaml     \\\n",
    "#     --source_file ./dataset.npy     \\\n",
    "#     --output_path ./demo_model.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
